{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba71b23-170d-43f8-8602-ffe91d914046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e199adf6-51de-480e-ad76-2a7b0ab18ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a63f1cd-5b62-455b-93b1-208e1ea7e408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import Dataset, train\n",
    "import gc \n",
    "\n",
    "def _recall_score(\n",
    "    preds: np.ndarray, data, threshold: float=0.5):\n",
    "    label = data.get_label()\n",
    "    preds = preds.reshape(7, -1).T\n",
    "    pred_label = np.argmax(preds, axis=1)\n",
    "    rs = recall_score(pred_label, label, average='macro', zero_division=0)\n",
    "\n",
    "    return '_recall_score', rs, True\n",
    "\n",
    "random_state = 42\n",
    "n_splits = 10\n",
    "clfs = []\n",
    "targets = ['crop']\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "categorical_feature = ['state', 'state_type','ISO3166-2-lvl4','municipality','county_type','municipality_type','region','county'] \n",
    "best_n_estimators = [300, 200, 200, 200, 400, 200, 200, 400, 400, 100]\n",
    "X = train_df.drop(targets, axis=1, errors='ignore')\n",
    "y = train_df[targets]   \n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    train_dataset = Dataset(data=X_train, label=y_train, categorical_feature=categorical_feature)\n",
    "    eval_dataset = Dataset(data=X_test, label =y_test, categorical_feature=categorical_feature)\n",
    "        \n",
    "    print(X_train.shape, y_train.shape)    \n",
    "    parameters = {\n",
    "            'n_estimators' : best_n_estimators[i],\n",
    "            'objective': 'multiclass',\n",
    "            'boosting': 'dart',\n",
    "            'feature_fraction': 0.5,\n",
    "            'uniform_drop' : True,\n",
    "            'max_depth' : 7,\n",
    "            'lambda_l2' : 0.01,\n",
    "            'bagging_freq': 125,\n",
    "            'min_split_gain': 0.001,\n",
    "            'num_class' : 7, \n",
    "            'drop_seed' : 7575,\n",
    "            'random_seed' : 42, \n",
    "            'verbose': -1,\n",
    "            'reg_lambda': 8.2532317400459,\n",
    "        }\n",
    "\n",
    "    clf = train(params = parameters,\n",
    "                   train_set = train_dataset,\n",
    "                   verbose_eval = 100,\n",
    "                   valid_sets=eval_dataset,\n",
    "                   feval=_recall_score,\n",
    "                   )\n",
    "    clfs.append(clf)\n",
    "\n",
    "    \n",
    "y_pred_lgb = np.zeros((sub.shape[0], 7))\n",
    "scores = []\n",
    "for n, clf in enumerate(clfs):\n",
    "    y_pred_lgb += clf.predict(test_df)\n",
    "    scores.append(clf.best_score['valid_0']['_recall_score'])\n",
    "\n",
    "y_pred_lgb /= n_splits\n",
    "print('_recall_score', np.mean(scores, dtype = 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a6e58-4aac-498b-85d4-4bcb36985aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from catboost import Pool, CatBoostClassifier, CatBoostRegressor \n",
    "import gc \n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "class RecallScore:\n",
    "    @staticmethod\n",
    "    def get_rs(pred_label, target):\n",
    "        return recall_score(pred_label, target, average='macro', zero_division=0)\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):          \n",
    "        pred_label = np.argmax(np.array(approxes).T, axis=1)\n",
    "        rs = 1 - self.get_rs(pred_label, target)\n",
    "        \n",
    "        return rs, 1\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "    \n",
    "random_state = 42\n",
    "n_splits = 10\n",
    "clfs = []\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "for train_index, test_index in kf.split(X, y):       \n",
    "    X_train, X_test = X.iloc[train_index].drop('weight', axis=1,  errors = 'ignore'), X.iloc[test_index].drop('weight', axis=1,  errors = 'ignore')\n",
    "    y_train, y_test = y.iloc[train_index].drop('weight', axis=1,  errors = 'ignore'), y.iloc[test_index].drop('weight', axis=1,  errors = 'ignore')\n",
    "\n",
    "    train_dataset = Pool(data=X_train, label=y_train, cat_features=cat_features)\n",
    "    eval_dataset = Pool(data=X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "    clf = CatBoostClassifier(iterations = 10000,\n",
    "                                loss_function='MultiClass',\n",
    "                                cat_features = cat_features,\n",
    "                                random_seed = random_state,  \n",
    "                                learning_rate = 0.005486411424635638,             \n",
    "                                colsample_bylevel = 0.4152157026818,\n",
    "                                subsample = 0.9563761143682146,\n",
    "                                l2_leaf_reg = 9.178962968420354,\n",
    "                                min_data_in_leaf = 243,\n",
    "                                bootstrap_type='Bernoulli',\n",
    "                                max_bin = 187,   \n",
    "                                task_type='CPU',\n",
    "                                early_stopping_rounds = 500,\n",
    "                                eval_metric=RecallScore())\n",
    "\n",
    "    clfs.append(clf)\n",
    "    clf.fit(train_dataset, eval_set=eval_dataset,\n",
    "                verbose = 200, use_best_model = True, plot = False)\n",
    "\n",
    "y_pred_catboost = np.zeros((sub.shape[0], 7))\n",
    "scores = []\n",
    "for n, clf in enumerate(clfs):\n",
    "    y_pred_catboost += clf.predict_proba(sub[final_features])\n",
    "    scores.append(1 - clfs[0].get_best_score()['validation']['RecallScore'])\n",
    "\n",
    "y_pred_catboost /= n_splits\n",
    "print('mean Recall', np.mean(scores['Recall'], dtype = 'float32'), f'По {len(clfs)} моделям')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c7a8b4c0-417d-4c14-80af-6386863b46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution = pd.read_csv('sample_solution.csv')\n",
    "sample_solution['crop'] = np.argmax(0.05*y_pred_catboost + 0.95*y_pred_lgb, axis=1)\n",
    "\n",
    "sub_num = 'best_ever'\n",
    "sample_solution.to_csv(f'livington_sub_{sub_num}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
